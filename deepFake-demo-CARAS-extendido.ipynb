{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"deepFake-demo-CARAS-extendido.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cdO_RxQZLahB"},"source":["# Demo de \"First Order Motion Model for Image Animation\" y \"Motion co-Segmentation\" para animar Caras y/o hacer intercambio de algunas partes\r\n","Fuentes: \r\n","\r\n","https://github.com/AliaksandrSiarohin/first-order-model\r\n","\r\n","https://github.com/AliaksandrSiarohin/motion-cosegmentation\r\n","\r\n","https://github.com/1adrianb/face-alignment\r\n"]},{"cell_type":"markdown","metadata":{"id":"GCDNKsEGLtR6"},"source":["1) Preparar el entorno:"]},{"cell_type":"code","metadata":{"id":"UCMFMJV7K-ag","collapsed":true,"cellView":"form"},"source":["#@title Clonar paquetes 'first-order-model' y 'motion-cosegmentation'\n","!git clone https://github.com/AliaksandrSiarohin/first-order-model\n","print(\"\\nFirst Order Motion Model  instalado.\")\n","\n","!git clone https://github.com/AliaksandrSiarohin/motion-cosegmentation motion-co-seg\n","print(\"\\nMotion-Cosegmentation instalado.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"NvIxcNj7Xgts"},"source":["#@title Clonar e instalar paquete 'face-alignment'\r\n","!git clone https://github.com/1adrianb/face-alignment\r\n","%cd face-alignment\r\n","!pip install -r requirements.txt\r\n","!python setup.py install\r\n","\r\n","# configura objeto para hacer detección de landmarks en imagen y video\r\n","import face_alignment\r\n","fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=False)#, face_detector='sfd')\r\n","\r\n","print(\"\\n\\nFace-alignment instalado.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zCZWe-F5fgSG","collapsed":true,"cellView":"form"},"source":["#@title Cargar Librerías\n","import sys\n","\n","import imageio\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from skimage.transform import resize\n","from IPython.display import HTML\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from skimage import io\n","from skimage import img_as_ubyte\n","\n","import PIL\n","from PIL import Image\n","from IPython.display import display as displayImage\n","import copy\n","import os\n","\n","import torch\n","import torch.nn.functional as F\n","import matplotlib.patches as mpatches\n","\n","print(\"Librerías cargadas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDbMA8R9OuUo","collapsed":true,"cellView":"form"},"source":["#@title Montar el drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","dir = '/content/gdrive/MyDrive/IA/pruebasDeepFake'  #@param {type:\"string\"}\n","subdir_ImagenesyVideos = 'demoCaras' #@param {type:\"string\"}\n","subdir_Modelos = 'checkpoints-models' #@param {type:\"string\"}\n","dirDatos = dir + '/' + subdir_ImagenesyVideos + '/'\n","dirModelos = dir + '/' + subdir_Modelos + '/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rW-ipQXPOWUo"},"source":["2) Cargar y preparar imagen y video:"]},{"cell_type":"code","metadata":{"id":"CFmRfDe_9L7X","collapsed":true,"cellView":"form"},"source":["#@title Funciones Auxiliares\r\n","\r\n","# tamaño requerido de la imagen y video para paquetes\r\n","tamRequeridoModelo = (256, 256)\r\n","\r\n","def hacerCropAuto(im, idCaraDetectada=0, ampliarCrop=0, muestraImg=True):\r\n","\r\n","  # prepara la imagen \r\n","  imagenSinCrop = copy.deepcopy( im )\r\n","  input = convImage2Array(im) * 255 \r\n","  \r\n","  # detecta los elementos de la imagen\r\n","  preds = fa.get_landmarks(input)\r\n","  if preds == None:\r\n","    if muestraImg:  \r\n","      print(\"No se detecta cara!\\n\")\r\n","    return im, None, im\r\n","\r\n","  # busca las coordenadas extremas para el crop\r\n","  minX, minY, maxX, maxY = None, None, None, None\r\n","  auxID = 0\r\n","  leyendasCara = []\r\n","  for ar in preds:\r\n","    leyendasCara.append( \"id_cara_ \" + str(auxID) )\r\n","    if idCaraDetectada>=0 and idCaraDetectada==auxID:\r\n","      for coordX in ar[:,0]:\r\n","          if minX == None or coordX < minX:\r\n","            minX = int(coordX)\r\n","          if maxX == None or coordX > maxX:\r\n","            maxX = int(coordX)\r\n","      for coordY in ar[:,1]:\r\n","          if minY == None or coordY < minY:\r\n","            minY = int(coordY)\r\n","          if maxY == None or coordY > maxY:\r\n","            maxY = int(coordY)\r\n","    auxID = auxID + 1 \r\n","  if minX == None or maxX == None or minY == None or maxY == None:\r\n","    if muestraImg:  \r\n","      print(\"No se encuentra cara_id seleccionada!\\n\")\r\n","    return im, None, im\r\n","      \r\n","  if muestraImg:\r\n","    print(\"\\nLímite de la cara detectada: (\", minX,\",\", minY, \") - (\", maxX, \",\", maxY, \")\\n\")\r\n","  if ampliarCrop>0:\r\n","    minX, maxX = minX-ampliarCrop, maxX+ampliarCrop\r\n","    minY, maxY = minY-ampliarCrop, maxY+ampliarCrop\r\n","\r\n","  # controla contra tamaño de la imagen\r\n","  if minX < 0:\r\n","    minX = 0\r\n","  if minY < 0:\r\n","    minY = 0\r\n","  if maxX > im.size[0]:\r\n","    maxX = im.size[0]\r\n","  if maxY > im.size[1]:\r\n","    maxY = im.size[1]\r\n","\r\n","  # realiza el crop de la imagen\r\n","  im = im.crop( (minX, minY, maxX, maxY) ) \r\n","\r\n","  # muesta la imagen si corresponde\r\n","  if muestraImg:\r\n","    fig, ax = plt.subplots(1, 2, figsize=(12,6))\r\n","    ax[0].imshow(imagenSinCrop)\r\n","    for detection in preds:\r\n","      ax[0].scatter(detection[:,0], detection[:,1], 5)\r\n","    ax[0].legend(leyendasCara)\r\n","    ax[1].imshow(im)\r\n","    ax[0].axis('off')\r\n","    ax[1].axis('off')\r\n","  \r\n","  return im, (minX, minY), imagenSinCrop\r\n","\r\n","\r\n","def deshacerCropAuto(hizoCrop, imOrig, imagNueva, coordXY):\r\n","\r\n","  # si está definido hace el crop\r\n","  if hizoCrop and coordXY!=None:\r\n","\r\n","    # le hace una copia a la imagen para no perderla\r\n","    imOrigCopy = copy.deepcopy( imOrig )\r\n","\r\n","    # copia una imagen en la posición correspondiente a la posición indicada\r\n","    imOrigCopy.paste(imagNueva, copy.deepcopy(coordXY) )\r\n","\r\n","    return imOrigCopy  \r\n","  \r\n","  else:\r\n","    return imagNueva\r\n","      \r\n","\r\n","def ajustarCoordResize(cords, tamOri, tamNuevo):\r\n","  if cords == None:\r\n","    return None\r\n","  if len(cords) != len(tamOri) or len(cords) != len(tamNuevo):\r\n","    return cords\r\n","  # realiza el ajuste\r\n","  Ncords = []\r\n","  for i in range(len(cords)):\r\n","    Ncords.append( int( cords[i]/(tamOri[i]/tamNuevo[i]) ) )\r\n","\r\n","  return Ncords\r\n","\r\n","def convImage2Array(im):\r\n","  return np.array(im).astype('float32') / 255.0\r\n","\r\n","\r\n","def convArray2Image(arIm, mult255=True):\r\n","  if mult255:\r\n","    multiplica = 255.0\r\n","  else:\r\n","    multiplica = 1.0\r\n","  return Image.fromarray((arIm*multiplica).astype(np.uint8))\r\n","\r\n","\r\n","def displayAnimacion(source, driving, generated=None):\r\n","    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\r\n","\r\n","    ims = []\r\n","    for i in range(len(driving)):\r\n","        if source is None:\r\n","          cols = [ driving[0] ]\r\n","        else:\r\n","          cols = [ source] \r\n","        cols.append(driving[i])\r\n","        if generated is not None:\r\n","            cols.append(generated[i])\r\n","        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\r\n","        plt.axis('off')\r\n","        ims.append([im])\r\n","\r\n","    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\r\n","    plt.close()\r\n","    return ani\r\n","\r\n","\r\n","def visualize_segmentation(image, network, supervised=False, hard=True, colormap='gist_rainbow'):\r\n","    with torch.no_grad():\r\n","        inp = torch.tensor(image[np.newaxis].astype(np.float32)).permute(0, 3, 1, 2).cuda()\r\n","        if supervised:\r\n","            inp = F.interpolate(inp, size=(512, 512))\r\n","            inp = (inp - network.mean) / network.std\r\n","            mask = torch.softmax(network(inp)[0], dim=1)\r\n","            mask = F.interpolate(mask, size=image.shape[:2])\r\n","        else:\r\n","            mask = network(inp)['segmentation']\r\n","            mask = F.interpolate(mask, size=image.shape[:2], mode='bilinear')\r\n","    \r\n","    if hard:\r\n","        mask = (torch.max(mask, dim=1, keepdim=True)[0] == mask).float()\r\n","    \r\n","    colormap = plt.get_cmap(colormap)\r\n","    num_segments = mask.shape[1]\r\n","    mask = mask.squeeze(0).permute(1, 2, 0).cpu().numpy()\r\n","    color_mask = 0\r\n","    patches = []\r\n","    for i in range(num_segments):\r\n","        if i != 0:\r\n","            color = np.array(colormap((i - 1) / (num_segments - 1)))[:3]\r\n","        else:\r\n","            color = np.array((0, 0, 0))\r\n","        patches.append(mpatches.Patch(color=color, label=str(i)))\r\n","        color_mask += mask[..., i:(i+1)] * color.reshape(1, 1, 3)\r\n","    \r\n","    fig, ax = plt.subplots(1, 2, figsize=(12,6))\r\n","    ax[0].imshow(color_mask)\r\n","    ax[1].imshow(0.3 * image + 0.7 * color_mask)\r\n","    ax[1].legend(handles=patches)\r\n","    ax[0].axis('off')\r\n","    ax[1].axis('off')\r\n","\r\n","    return color_mask\r\n","\r\n","print(\"Funciones auxiliares definidas.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1fsKdfRFzoO3","collapsed":true,"cellView":"form"},"source":["#@title Seleccionar y preparar la imagen\r\n","\r\n","# selecciona la imagen a procesar\r\n","imagen_Seleccionada = \"moises.jpg\" #@param ['sample1-shrek.png', 'sample2-chucky.png' , 'sample3-it.png' , 'sample4-socrates.png','sample5-putin.png','sample6-downeyjr.png', 'sample7-wryder.png', 'sample8.png', 'sample9.png', 'monaLisa.jpg', 'moises.jpg', 'yo.png', 'yoda.jpeg', 'babyYoda.jpeg', 'zombie1.jpg', 'zombie2.jpg' ] {allow-input: false}\r\n","imagenFuente = dirDatos + imagen_Seleccionada\r\n","\r\n","imagen_hace_Crop_cara = True #@param {type:\"boolean\"}\r\n","imagen_id_cara_detectada = 2 #@param {type:\"number\"}\r\n","imagen_ampliar_Crop_cara = 500 #@param {type:\"number\"}\r\n","imagen_espejada = True #@param {type:\"boolean\"}\r\n","\r\n","# carga la imagen\r\n","print(imagenFuente)\r\n","im = Image.open( imagenFuente )\r\n","print(\"Imagen cargada.\")\r\n","\r\n","# fuerza a RGB\r\n","im = im.convert(\"RGB\")\r\n","\r\n","# obtiene el tamaño original de la imagen\r\n","imgTamOri = im.size\r\n","print(\"Tamaño original: \", imgTamOri)\r\n","\r\n","# realiza imagen espejada (opcional)\r\n","if imagen_espejada:\r\n","  im = im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\r\n","\r\n","print(\"\\n\")\r\n","if imagen_hace_Crop_cara: \r\n","  # realiza el crop automatico\r\n","  im, imgCoordCrop, imagenSinCrop = hacerCropAuto(im, imagen_id_cara_detectada, imagen_ampliar_Crop_cara)\r\n","  imgTamCrop = im.size\r\n","  print(imgTamCrop)\r\n","  imgHizoCrop = True\r\n","else:\r\n","  # no realiza el crop automatico\r\n","  imagenSinCrop = im\r\n","  imgTamCrop = imgTamOri\r\n","  imgHizoCrop = False\r\n","  imgCoordCrop = None\r\n","  displayImage(im)\r\n","\r\n","# cambia tamaño de la imagen a procesar a 256x256\r\n","im = im.resize(tamRequeridoModelo, Image.ANTIALIAS)\r\n","print(\"Nuevo tamaño luego del resize: \", im.size)\r\n","\r\n","# ajusta el tamaño de las coordenadas de crop\r\n","if imgCoordCrop!=None:\r\n","  imgCoordCrop = ajustarCoordResize(imgCoordCrop, imgTamCrop, tamRequeridoModelo)  \r\n","\r\n","# cambia tamaño de la imagen sin crop \r\n","imagenSinCrop = imagenSinCrop.resize( ajustarCoordResize(imgTamOri, imgTamCrop, tamRequeridoModelo), Image.ANTIALIAS)\r\n","  \r\n","# convierte imagen a vector de números\r\n","source_image = convImage2Array(im)\r\n","print(\"Tamaño del vector de la imagen: \", source_image.shape)\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGtrNo1W4uHh","collapsed":true,"cellView":"form"},"source":["#@title Seleccionar el video y determina parámetros\n","\n","# selecciona el video a procesar\n","video_seleccionado =  \"sample2-dicaprio.mp4\" #@param [ 'sample1-obama.mp4', 'sample2-dicaprio.mp4', 'sample3-trump.mp4', 'sample4.mp4', 'jackNicholson.mp4', 'JimCarrey1.mp4', 'JimCarrey2.mp4'  ] {allow-input: true}\n","videoFuente = dirDatos + video_seleccionado\n","print(videoFuente)\n","\n","video_hace_Crop_cara = False #@param {type:\"boolean\"}\n","video_id_cara_detectada = 0 #@param {type:\"number\"}\n","video_ampliar_Crop_cara =  80 #@param {type:\"number\"}\n","video_tomar_segmento_usar = False #@param {type:\"boolean\"}\n","video_ini_segmento_usar = 330 #@param {type:\"number\"}\n","video_fin_segmento_usar = 550 #@param {type:\"number\"}\n","\n","# carga video\n","reader = imageio.get_reader( videoFuente )\n","if videoFuente.find('mp4')>=0:\n","  fps = reader.get_meta_data()['fps']\n","else:\n","  fps = 25\n","driving_video = []\n","try:\n","    auxContador = 0\n","    for imVideo in reader:\n","      if not(video_tomar_segmento_usar) or (auxContador >= video_ini_segmento_usar and auxContador <= video_fin_segmento_usar): \n","        # aplica el crop si corresponde \n","        # y muestra solo la primera imagen como ejemplo\n","        img = convArray2Image(imVideo, mult255=False)\n","        if video_hace_Crop_cara:\n","          img, _, _ = hacerCropAuto(img, video_id_cara_detectada, video_ampliar_Crop_cara)\n","        else:\n","           displayImage(img)\n","        # cambia el tamaño de la imagen\n","        img = img.resize(tamRequeridoModelo, Image.ANTIALIAS)                \n","        break\n","      auxContador = auxContador + 1\n","except RuntimeError:\n","    pass\n","reader.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWq2h1XJ-orM","collapsed":true,"cellView":"form"},"source":["#@title Preparar todo el video\r\n","\r\n","# carga video\r\n","reader = imageio.get_reader( videoFuente )\r\n","if videoFuente.find('mp4')>=0:\r\n","  fps = reader.get_meta_data()['fps']\r\n","else:\r\n","  fps = 15\r\n","driving_video = []\r\n","driving_video_sinCrop = []\r\n","driving_video_coordsCrop = []\r\n","try:\r\n","    i = 0\r\n","    auxContador = 0\r\n","    for imVideo in reader:  \r\n","      if not(video_tomar_segmento_usar) or (auxContador >= video_ini_segmento_usar and auxContador <= video_fin_segmento_usar): \r\n","        # procesa los frames y las agrega al vector    \r\n","        img = convArray2Image(imVideo, mult255=False)\r\n","        # hace el crop si corresponde y guarda info \r\n","        # para reconstruir luego imagen original        \r\n","        if video_hace_Crop_cara:\r\n","          img, coordCrop, imgOri = hacerCropAuto(img, video_id_cara_detectada, video_ampliar_Crop_cara, False)\r\n","          #coordCrop = ajustarCoordResize(coordCrop, imgOri.size, tamRequeridoModelo)  \r\n","          driving_video_coordsCrop.append( coordCrop )\r\n","          #imgOri = imgOri.resize( ajustarCoordResize(imgOri.size, img.size, tamRequeridoModelo), Image.ANTIALIAS)\r\n","          driving_video_sinCrop.append( imgOri )\r\n","        # cambia el tamaño de la imagen\r\n","        img = img.resize(tamRequeridoModelo, Image.ANTIALIAS)\r\n","        # agrega el frame a la lista\r\n","        driving_video.append( convImage2Array(img) )      \r\n","      auxContador = auxContador + 1\r\n","except RuntimeError:\r\n","    pass\r\n","reader.close()\r\n","\r\n","print(\"Video cargado.\")\r\n","print(\"Duración del video total: \", len(driving_video), \" frames.\")\r\n","\r\n","# cambia tamaño del video a 256x256\r\n","##driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\r\n","\r\n","# muestra imagen con video\r\n","HTML(displayAnimacion(source_image, driving_video).to_html5_video())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fdFdasHEj3t7"},"source":["3) Genera la animación de la cara de la imagen con gesto del video:"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"h-2POM2CRlBu","cellView":"form"},"source":["#@title Cargar checkpoint del modelo 'first-order-mode' ya entrenado\r\n","\r\n","if '/content/motion-co-seg' in sys.path:\r\n","  sys.path.remove('/content/motion-co-seg')\r\n","if '/content/motion-co-seg/modules' in sys.path:\r\n","  sys.path.remove('/content/motion-co-seg/modules')\r\n","# tiene que borrar este modulo que está en ambos paquetes \r\n","# pero con diferente veriones\r\n","if \"logger\" in sys.modules:\r\n","  del sys.modules[\"logger\"]\r\n","\r\n","sys.path.append('/content/first-order-model')\r\n","sys.path.append('/content/first-order-model/modules')\r\n","from demo import make_animation\r\n","from demo import load_checkpoints as fom_load_checkpoints\r\n","\r\n","\r\n","print(\"Librerías cargadas de 'first-order-mode'.\")\r\n","\r\n","\r\n","generator, kp_detector = fom_load_checkpoints(config_path = '/content/first-order-model/config/vox-256.yaml', \r\n","                            checkpoint_path = dirModelos + 'vox-cpk.pth.tar')\r\n","\r\n","print(\"Modelo 'first-order-mode' cargado.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SB12II11kF4c","collapsed":true,"cellView":"form"},"source":["#@title Aplica el modelo para generar nueva animación\n","\n","# genera animación aplicando el modelo\n","tipo_Desplazamiento = 'relativo'  #@param ['relativo', 'absoluto']\n","if tipo_Desplazamiento == 'relativo': \n","  # usa desplazamientos relativos (queda mejor)\n","  predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\n","else:\n","  # usa desplazamientos relativos (queda deformado)\n","  predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=False, adapt_movement_scale=True)\n","\n","# muestra la animación\n","HTML(displayAnimacion(source_image, driving_video, predictions).to_html5_video())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NjgRh0nfWGYt","cellView":"form"},"source":["#@title Agrega bordes de la imagen en la animación (si corresponde)\r\n","\r\n","animacion = []\r\n","if imgHizoCrop:\r\n","  \r\n","  # toma los frames de la animación generada\r\n","  # y las inserta dentro de la imagen original\r\n","  # para generar animación mejorada\r\n","  for imP in predictions:\r\n","    img = convArray2Image(imP, mult255=True)\r\n","    nImag = deshacerCropAuto(imgHizoCrop, imagenSinCrop, img, imgCoordCrop)\r\n","    animacion.append( convImage2Array(nImag) ) \r\n","else:\r\n","  # como no se hizo crop, no hace nada\r\n","  animacion = predictions\r\n","\r\n","HTML(displayAnimacion(None, animacion).to_html5_video())  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fq_bF9wKFgr8","cellView":"form"},"source":["#@title Exporta la animación\r\n","\r\n","if animacion == None:\r\n","  animacion = predictions\r\n","\r\n","# graba el video para poder bajarlo (opcional)\r\n","tipoExportacion = \"GIF\" #@param [\"no\", \"GIF\", \"MP4\"]\r\n","if tipoExportacion != \"no\":\r\n","  expName = '/content/' + 'vfake_' + tipo_Desplazamiento[:3] + '_' + os.path.splitext(imagen_Seleccionada)[0] + '_' + os.path.splitext(video_seleccionado)[0]   \r\n","  if tipoExportacion == \"MP4\":\r\n","    expName = expName + '.mp4'\r\n","  elif tipoExportacion == \"GIF\":\r\n","    expName = expName + '.gif'\r\n","  imageio.mimsave(expName, [img_as_ubyte(frame) for frame in animacion], fps=fps)\r\n","  print(expName, \" generado en el disco temporal del ambiente.\")\r\n","\r\n","HTML(displayAnimacion(None, animacion).to_html5_video())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"esKwCUYGMZ5C"},"source":["4) Genera la animación con intercambio de elementos:"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"dnywvmHCRYTy","cellView":"form"},"source":["#@title Cargar checkpoint del modelo 'motion-co-seg' ya entrenado\r\n","\r\n","\r\n","if '/content/first-order-model' in sys.path:\r\n","  sys.path.remove('/content/first-order-model')\r\n","if '/content/first-order-model/modules' in sys.path:\r\n","  sys.path.remove('/content/first-order-model/modules')\r\n","# tiene que borrar este modulo que está en ambos paquetes \r\n","# pero con diferente veriones\r\n","if \"logger\" in sys.modules:\r\n","  del sys.modules[\"logger\"]\r\n","\r\n","sys.path.append('/content/motion-co-seg')\r\n","sys.path.append('/content/motion-co-seg/modules')\r\n","from part_swap import load_checkpoints as swap_load_checkpoints\r\n","from part_swap import make_video\r\n","\r\n","print(\"Librerías cargadas de 'motion-co-seg'.\")\r\n","\r\n","#%cd /content/motion-co-seg\r\n","tipo_checkpoint_de_intercambio = \"10 segmentos\" \r\n","if  tipo_checkpoint_de_intercambio == \"10 segmentos\":\r\n","  configSgmt = '/content/motion-co-seg/config/vox-256-sem-10segments.yaml'\r\n","  chpntSgmto = dirModelos + 'vox-10segments.pth.tar'\r\n","# Nota: hay también de 5 y 15 segmentos pero como ejemplo se usa solo este\r\n","# en caso que se desea usar alguno de los otros, bajar de la fuente y subir al drive\r\n","\r\n","reconstruction_module, segmentation_module = swap_load_checkpoints(config = configSgmt, \r\n","                                               checkpoint = chpntSgmto,\r\n","                                               blend_scale = 1)\r\n","\r\n","print(\"Modelo 'motion-co-seg' cargado.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"05QVOGC8LYHh","collapsed":true,"cellView":"form"},"source":["#@title Mostrar segmentos detectados en la imagen\r\n","\r\n","%matplotlib inline\r\n","visualize_segmentation(source_image, segmentation_module, hard=True)\r\n","plt.show()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lM84s2txPrkA","collapsed":true,"cellView":"form"},"source":["#@title Aplica los segmentos seleccionados de la imagen en el video\n","\n","lista_segmentos_intercambiar = \"2,4,7\" #@param {type:\"string\"}\n","swap_index_list = np.array(lista_segmentos_intercambiar.split(\",\")).astype(np.uint8)\n","if len(swap_index_list) == 0:\n","  swap_index_list.append( 1 )\n","else:\n","  swap_index_list.sort()\n","\n","# genera animación aplicando las partes seleccionadas de la imagen\n","swap_predictions = make_video(swap_index=swap_index_list.tolist(), source_image = source_image, target_video = driving_video,\n","                             segmentation_module=segmentation_module, reconstruction_module=reconstruction_module)\n","swap_animacion = None\n","\n","# muestra la animación\n","HTML(displayAnimacion(source_image, driving_video, swap_predictions).to_html5_video())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"cpHJckbzHWSp"},"source":["#@title Agrega bordes del video en la animación (si corresponde)\r\n","\r\n","swap_animacion = []\r\n","if len(driving_video_sinCrop)>0 and len(driving_video_coordsCrop)>0:\r\n","  # toma los frames de la animación generada\r\n","  # y las inserta dentro de la imagen original\r\n","  # para generar animación mejorada\r\n","  for i in range(len(swap_predictions)):\r\n","    img = convArray2Image(swap_predictions[i], mult255=True)\r\n","    nImag = deshacerCropAuto(True, driving_video_sinCrop[i], img, driving_video_coordsCrop[i])\r\n","    swap_animacion.append( convImage2Array(nImag) ) \r\n","else:\r\n","  # como no se hizo crop, no hace nada\r\n","  swap_animacion = swap_predictions\r\n","\r\n","HTML(displayAnimacion(None, swap_animacion).to_html5_video())  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vnYLABgCVAVR","cellView":"form"},"source":["#@title Exporta la animación\r\n","# graba el video para poder bajarlo (opcional)\r\n","\r\n","if swap_animacion == None:\r\n","  swap_animacion = swap_predictions\r\n","\r\n","tipoExportacion = \"no\" #@param [\"no\", \"GIF\", \"MP4\"]\r\n","if tipoExportacion != \"no\":\r\n","  expName = '/content/' + 'vfake_swap_' + os.path.splitext(imagen_Seleccionada)[0] + '_' + os.path.splitext(video_seleccionado)[0]   \r\n","  if tipoExportacion == \"MP4\":\r\n","    expName = expName + '.mp4'\r\n","  elif tipoExportacion == \"GIF\":\r\n","    expName = expName + '.gif'\r\n","  imageio.mimsave(expName, [img_as_ubyte(frame) for frame in swap_animacion], fps=fps)\r\n","  print(expName, \" generado en el disco temporal del ambiente.\")\r\n","\r\n","HTML(displayAnimacion(None, swap_animacion).to_html5_video())"],"execution_count":null,"outputs":[]}]}